{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c273b91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 33 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 79 0 (offset 0)\n",
      "Ignoring wrong pointing object 84 0 (offset 0)\n",
      "Ignoring wrong pointing object 86 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 93 0 (offset 0)\n",
      "Ignoring wrong pointing object 98 0 (offset 0)\n",
      "Ignoring wrong pointing object 101 0 (offset 0)\n",
      "Number of tokens (1445) exceeded maximum context length (512).\n",
      "Number of tokens (1446) exceeded maximum context length (512).\n",
      "Number of tokens (1447) exceeded maximum context length (512).\n",
      "Number of tokens (1448) exceeded maximum context length (512).\n",
      "Number of tokens (1449) exceeded maximum context length (512).\n",
      "Number of tokens (1450) exceeded maximum context length (512).\n",
      "Number of tokens (1451) exceeded maximum context length (512).\n",
      "Number of tokens (1452) exceeded maximum context length (512).\n",
      "Number of tokens (1453) exceeded maximum context length (512).\n",
      "Number of tokens (1454) exceeded maximum context length (512).\n",
      "Number of tokens (1455) exceeded maximum context length (512).\n",
      "Number of tokens (1456) exceeded maximum context length (512).\n",
      "Number of tokens (1457) exceeded maximum context length (512).\n",
      "Number of tokens (1458) exceeded maximum context length (512).\n",
      "Number of tokens (1459) exceeded maximum context length (512).\n",
      "Number of tokens (1460) exceeded maximum context length (512).\n",
      "Number of tokens (1461) exceeded maximum context length (512).\n",
      "Number of tokens (1462) exceeded maximum context length (512).\n",
      "Number of tokens (1463) exceeded maximum context length (512).\n",
      "Number of tokens (1464) exceeded maximum context length (512).\n",
      "Number of tokens (1465) exceeded maximum context length (512).\n",
      "Number of tokens (1466) exceeded maximum context length (512).\n",
      "Number of tokens (1467) exceeded maximum context length (512).\n",
      "Number of tokens (1468) exceeded maximum context length (512).\n",
      "Number of tokens (1469) exceeded maximum context length (512).\n",
      "Number of tokens (1470) exceeded maximum context length (512).\n",
      "Number of tokens (1471) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "Compoundsounder: chromium: chromium: chromium:\n",
      "Answer based on this question 09\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.llms import CTransformers\n",
    "import os\n",
    "\n",
    "# === Load and split PDF ===\n",
    "loader = PyPDFLoader(\"Chapter_17_Chemical_carcinogens.pdf\")\n",
    "data = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "docs = splitter.split_documents(data)\n",
    "\n",
    "# === Embed and persist ===\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(docs, embedding=embedding_function, persist_directory=os.getcwd())\n",
    "\n",
    "# === Define retriever ===\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# === Prompt template ===\n",
    "template = \"\"\"Answer the question based on the following context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# === Load GGUF model locally via ctransformers ===\n",
    "llm = CTransformers(\n",
    "    model=\"C:\\Endava\\EndevLocal\\AI_speech_text_summarize\\mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\"\n",
    ")\n",
    "\n",
    "# === Build RAG chain ===\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# === Run it ===\n",
    "question = \"What compounds generate Breast cancer?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22cffbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a93a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
